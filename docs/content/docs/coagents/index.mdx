---
title: Introduction to CoAgents
description: Everything you need to deeply integrate LangGraph agents into react applications.

---

import { BiSolidMessage as TextIcon } from "react-icons/bi";
import { VscJson as JsonIcon } from "react-icons/vsc";
import { FaDiscord } from "react-icons/fa";
import Link from "next/link";
import { YouTubeVideo } from "@/components/react/youtube-video";
import { CoAgentsEnterpriseCTA } from "@/components/react/coagents/coagents-enterprise-cta.tsx";
import {
  CoAgentsFeatureToggle,
  CoAgentsFeatureRender,
} from "@/components/react/coagents/coagents-features.tsx";
import { DynamicContentWrapper } from "@/components/react/dynamic-content-wrapper";

<Frame className="-mt-12">
  <img
    src="/images/CoAgents.gif"
    alt="CoAgents demonstration"
    className="w-auto"
  />
</Frame>

CopilotKit's CoAgents provides everything you need to deeply integrate LangGraph agents into react applications.

  <Link
    href="https://github.com/CopilotKit/CopilotKit/blob/main/examples/coagents-research-canvas/readme.md"
    className="text-primary-600 decoration-from-font underline [text-underline-position:from-font]"
  >
    Check out Research Canvas demo, built with CoAgents
  </Link>

<div className="flex justify-center my-12">
  <YouTubeVideo videoId="nBephBv4zr0" defaultPlaybackRate={1.25} />
</div>

<Frame>
  <img
    src="/images/CoAgents.gif"
    alt="CoAgents demonstration"
    className="w-auto"
  />
</Frame>


## The Core Features of a CoAgent

<DynamicContentWrapper>
<CoAgentsFeatureToggle />

<CoAgentsFeatureRender feature="generative-ui">
  ### Generative UI

Generative UI allows you to create dynamic user interfaces with AI-generated components, inside a chat UI.

```tsx
useCoAgentStateRender({
  // the name of the agent
  name: "car_rental_agent",

  // this is optional: the node name to render generative UI for. If left empty, renders for every node.
  nodeName: "confirm_node",

  // render can be a function or a string, just like useCopilotAction
  render: ({ state, status }) => {
    if (status === "inProgress") {
      return <div> Generating response: {state.response} </div>;
    } else {
      return <div> Done generating response </div>;
    }
  },
});
```

<Frame>
  <img src="/images/coagents/json-feedback.png" alt="JSON feedback example" />
</Frame>

</CoAgentsFeatureRender>

<CoAgentsFeatureRender feature="stream-agent-state">
  ### Stream agent state

  <Steps>
    ### Frontend

    All you need to do to get the current LangGraph agent state is call `useCoAgent`.

    ```tsx
    const { state } = useCoAgent({
      name: "search_agent", // the name of the agent
    });
    ```

    ### LangGraph
    The LangGraph state only updates when leaving a LangGraph node.
    If you want to stream state updates to the frontend as they are generated, you can do so by one of the following methods:

    #### Intercept tool calls

    If you would like to stream **intermediate** state to the frontend, you can do so by treating (streaming) tool call arguments as intermediate state:

    ```python
    # in python code:
    config = copilotkit_customize_config(
        config,
        emit_intermediate_state=[
            {
                "state_key": "steps", # key on the LangGraph state to be updated
                "tool": "search", # tool call
                "tool_argument": "steps" # argument of the tool call interpreted as intermediate state
            },
        ]
    )

    # ...

    response = await ChatOpenAI(model="gpt-4").bind_tools([search_tool], parallel_tool_calls=False, tool_choice="search").ainvoke([
        *state["messages"],
        SystemMessage(
            content=system_message
        )
    ], config)
    ```

    #### Manually Emit State

    You can imperatively emit state by calling `copilotkit_emit_state`:

    ```python
    # imperative function:
    copilotkit_emit_state(config, {"key": value} )
    ```

    #### Manually Emit Messages

    To manually emit messages to the frontend, call `copilotkit_emit_message`:

    ```python
    # imperative function:
    copilotkit_emit_message(config, "Hello, world!")
    ```

  </Steps>

<Frame>
  <img src="/images/coagents/intermediate-state.gif" />
</Frame>

</CoAgentsFeatureRender>

<CoAgentsFeatureRender feature="share-agent-state">

### Share Agent State

Sharing agent state allows for collaboration and persistence across different sessions or users. Here's how you can implement this feature:

```typescript
const { state, setState, start, stop, run } = useCoAgent({
  name: "search_agent",
});

// ...
setState(newStateEditedByUser);
run(
  () =>
    new TextMessage({
      role: MessageRole.System,
      content: "the user has updated the state",
    })
); // optionally provide a hint about why the agent state changed.
```

Just like before, we use the `state` variable on `useCoAgent` to receive the latest agent state.
Now we additionally intercept 4 more of `useCoAgent`'s returned values:

- `setState`: A function to update the agent's state manually
- `start`: A function to initiate the agent's execution
- `stop`: A function to halt the agent's execution
- `run`: A function to re-run the agent, after updating the state. Optionally include a hint for why the state changed.

</CoAgentsFeatureRender>

<CoAgentsFeatureRender feature="agent-q-and-a">
  ### Agent Q&A

Agents can easily and intentionally ask the user questions. With support for:

- **Text Feedback:** Via the chat UI.
- **Structured (JSON) Feedback:** Via fully custom UI/UX anywhere in your application (chat UI, modals, popups, forms, etc).

<br />

<div className="flex gap-2 w-full my-2">
  <div className="flex-1 border bg-white rounded-lg shadow-md p-4">
    <div className="flex items-center justify-center gap-2 font-semibold">
      <div className="bg-indigo-500 rounded-md w-7 h-7 text-white flex items-center justify-center">
        <TextIcon className="w-4 h-4" />
      </div>
      <span className="dark:text-black">Text Feedback</span>
    </div>
    <div className="italic py-4">
      <img
        src="/images/coagents/text-feedback.png"
        className="rounded-md border"
      />
    </div>
  </div>
  <div className="flex-1 border bg-white rounded-lg shadow-md p-4">
    <div className="flex items-center justify-center gap-2 font-semibold">
      <div className="bg-indigo-500 rounded-md w-7 h-7 text-white  flex items-center justify-center">
        <JsonIcon className="w-5 h-5" />
      </div>
      <span className="dark:text-black">Structured (JSON) Feedback</span>
    </div>
    <div className="italic py-4">
      <img
        src="/images/coagents/json-feedback.png"
        className="rounded-md border"
      />
    </div>
  </div>
</div>

We will soon add native & seamless Agent Q&A support in `useCoAgentStateRender`.

In the meantime, you can achieve agent Q&A in the following way:

1. Use `useCoAgentStateRender` to render your "Question" LangGraph node (via the exposed state).
2. In your LangGraph, go to an `END` node, or use a breakpoint, to wait for user input.
3. In the `useCoAgentStateRender` render function, call `setState` provided by `useCoAgent` to provide the "answer" in the graph state.
4. After the answer is provided via the agent state, navigate to your relevant 'answer' node. For convenience, [you can use the `then` argument on LangGraph's `add_conditional_edges`](https://langchain-ai.github.io/langgraph/reference/graphs/#stategraph)

</CoAgentsFeatureRender>

<CoAgentsFeatureToggle />
</DynamicContentWrapper>

<CoAgentsEnterpriseCTA />
